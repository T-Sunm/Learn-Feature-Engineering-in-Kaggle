{
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "formats": "ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1828856,
          "sourceType": "datasetVersion",
          "datasetId": 933090
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Exercise: Principal Component Analysis",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sunm/Learn-Feature-Engineering-in-Kaggle/blob/main/Exercise_Principal_Component_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'fe-course-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F933090%2F1828856%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240926%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240926T134618Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2f9cde9f15f83bf8611a81a466d4f9327a3c750943da13425c15feea55081c6e57a3b1f6c2cb762ef1f4122173d14f8f9bdeac6581c215da185309c333dc2dc26098510463d4136575b51f1ef01961567ef42a4b2860f8344b0fefcd3be22f2fcf72cb27035f966d32ecb19fecf92c3633b6a7038fca10f7731f4a302bd9973f3675ab455743c220bfc8248b2fd70f0ab604de45f5edb6d48f5b11fbd9cf1195787ed9f7ad3e9adcaadaa153a2d88f98095ba021a155ec4836ed19e1c6bd87a67cf61f03d3859974dc96e978e4dfb6d36b3e8ed42925eef8956511925c0f1b0472e94b94567b324199e1fe01b7fd20c1415c3703e13cd2f392d5b54e45b9870c'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "QgrqjQv-lJZO"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook is an exercise in the [Feature Engineering](https://www.kaggle.com/learn/feature-engineering) course.  You can reference the tutorial at [this link](https://www.kaggle.com/ryanholbrook/principal-component-analysis).**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "F-gWSHm_lJZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction #\n",
        "\n",
        "In this exercise, you'll work through several applications of PCA to the [*Ames*](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) dataset."
      ],
      "metadata": {
        "id": "tSgq2SMslJZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this cell to set everything up!"
      ],
      "metadata": {
        "id": "TJBMqkvClJZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup feedback system\n",
        "from learntools.core import binder\n",
        "binder.bind(globals())\n",
        "from learntools.feature_engineering_new.ex5 import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Set Matplotlib defaults\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\n",
        "    \"axes\",\n",
        "    labelweight=\"bold\",\n",
        "    labelsize=\"large\",\n",
        "    titleweight=\"bold\",\n",
        "    titlesize=14,\n",
        "    titlepad=10,\n",
        ")\n",
        "\n",
        "\n",
        "def apply_pca(X, standardize=True):\n",
        "    # Standardize\n",
        "    if standardize:\n",
        "        X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "    # Create principal components\n",
        "    pca = PCA()\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    # Convert to dataframe\n",
        "    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
        "    X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
        "    # Create loadings\n",
        "    loadings = pd.DataFrame(\n",
        "        pca.components_.T,  # transpose the matrix of loadings\n",
        "        columns=component_names,  # so the columns are the principal components\n",
        "        index=X.columns,  # and the rows are the original features\n",
        "    )\n",
        "    return pca, X_pca, loadings\n",
        "\n",
        "\n",
        "def plot_variance(pca, width=8, dpi=100):\n",
        "    # Create figure\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    n = pca.n_components_\n",
        "    grid = np.arange(1, n + 1)\n",
        "    # Explained variance\n",
        "    evr = pca.explained_variance_ratio_\n",
        "    axs[0].bar(grid, evr)\n",
        "    axs[0].set(\n",
        "        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    # Cumulative Variance\n",
        "    cv = np.cumsum(evr)\n",
        "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
        "    axs[1].set(\n",
        "        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    # Set up figure\n",
        "    fig.set(figwidth=8, dpi=100)\n",
        "    return axs\n",
        "\n",
        "\n",
        "def make_mi_scores(X, y):\n",
        "    X = X.copy()\n",
        "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
        "        X[colname], _ = X[colname].factorize()\n",
        "    # All discrete features should now have integer dtypes\n",
        "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
        "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "    return mi_scores\n",
        "\n",
        "\n",
        "def score_dataset(X, y, model=XGBRegressor()):\n",
        "    # Label encoding for categoricals\n",
        "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
        "        X[colname], _ = X[colname].factorize()\n",
        "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
        "    score = cross_val_score(\n",
        "        model, X, y, cv=5, scoring=\"neg_mean_squared_log_error\",\n",
        "    )\n",
        "    score = -1 * score.mean()\n",
        "    score = np.sqrt(score)\n",
        "    return score\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"../input/fe-course-data/ames.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T05:08:16.613871Z",
          "iopub.execute_input": "2024-09-24T05:08:16.614346Z",
          "iopub.status.idle": "2024-09-24T05:08:20.569716Z",
          "shell.execute_reply.started": "2024-09-24T05:08:16.614303Z",
          "shell.execute_reply": "2024-09-24T05:08:20.568516Z"
        },
        "trusted": true,
        "id": "_XT1w0D4lJZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's choose a few features that are highly correlated with our target, `SalePrice`.\n"
      ],
      "metadata": {
        "id": "imHVWzONlJZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = [\n",
        "    \"GarageArea\",\n",
        "    \"YearRemodAdd\",\n",
        "    \"TotalBsmtSF\",\n",
        "    \"GrLivArea\",\n",
        "]\n",
        "\n",
        "print(\"Correlation with SalePrice:\\n\")\n",
        "print(df[features].corrwith(df.SalePrice))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T05:08:20.571794Z",
          "iopub.execute_input": "2024-09-24T05:08:20.573054Z",
          "iopub.status.idle": "2024-09-24T05:08:20.601458Z",
          "shell.execute_reply.started": "2024-09-24T05:08:20.572993Z",
          "shell.execute_reply": "2024-09-24T05:08:20.599934Z"
        },
        "trusted": true,
        "id": "Ntuu8GUnlJZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll rely on PCA to untangle the correlational structure of these features and suggest relationships that might be usefully modeled with new features.\n",
        "\n",
        "Run this cell to apply PCA and extract the loadings."
      ],
      "metadata": {
        "id": "NdGbvXyqlJZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.copy()\n",
        "y = X.pop(\"SalePrice\")\n",
        "X = X.loc[:, features]\n",
        "\n",
        "# `apply_pca`, defined above, reproduces the code from the tutorial\n",
        "pca, X_pca, loadings = apply_pca(X)\n",
        "print(loadings)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T05:08:54.634073Z",
          "iopub.execute_input": "2024-09-24T05:08:54.634524Z",
          "iopub.status.idle": "2024-09-24T05:08:54.670564Z",
          "shell.execute_reply.started": "2024-09-24T05:08:54.63448Z",
          "shell.execute_reply": "2024-09-24T05:08:54.669323Z"
        },
        "trusted": true,
        "id": "yBC-2SW4lJZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Interpret Component Loadings\n",
        "\n",
        "Look at the loadings for components `PC1` and `PC3`. Can you think of a description of what kind of contrast each component has captured? After you've thought about it, run the next cell for a solution."
      ],
      "metadata": {
        "id": "Zj5SViIBlJZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_pca"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T05:20:54.192154Z",
          "iopub.execute_input": "2024-09-24T05:20:54.192624Z",
          "iopub.status.idle": "2024-09-24T05:20:54.208167Z",
          "shell.execute_reply.started": "2024-09-24T05:20:54.192581Z",
          "shell.execute_reply": "2024-09-24T05:20:54.206986Z"
        },
        "trusted": true,
        "id": "KuvHQ8_YlJZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the solution (Run this cell to receive credit!)\n",
        "q_1.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T05:09:59.136161Z",
          "iopub.execute_input": "2024-09-24T05:09:59.137368Z",
          "iopub.status.idle": "2024-09-24T05:09:59.148516Z",
          "shell.execute_reply.started": "2024-09-24T05:09:59.137316Z",
          "shell.execute_reply": "2024-09-24T05:09:59.147258Z"
        },
        "trusted": true,
        "id": "12JhaUzRlJZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------------------------------------\n",
        "\n",
        "Your goal in this question is to use the results of PCA to discover one or more new features that improve the performance of your model. One option is to create features inspired by the loadings, like we did in the tutorial. Another option is to use the components themselves as features (that is, add one or more columns of `X_pca` to `X`).\n",
        "\n",
        "# 2) Create New Features\n",
        "\n",
        "Add one or more new features to the dataset `X`. For a correct solution, get a validation score below 0.140 RMSLE. (If you get stuck, feel free to use the `hint` below!)"
      ],
      "metadata": {
        "id": "9KAagb07lJZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = make_mi_scores(X_pca, y)\n",
        "mi_scores"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T05:18:03.522084Z",
          "iopub.execute_input": "2024-09-24T05:18:03.52254Z",
          "iopub.status.idle": "2024-09-24T05:18:03.611363Z",
          "shell.execute_reply.started": "2024-09-24T05:18:03.522494Z",
          "shell.execute_reply": "2024-09-24T05:18:03.609847Z"
        },
        "trusted": true,
        "id": "9RcTFiA9lJZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.copy()\n",
        "y = X.pop(\"SalePrice\")\n",
        "\n",
        "X[\"PC1\"] = X_pca['PC1']\n",
        "\n",
        "score = score_dataset(X, y)\n",
        "print(f\"Your score: {score:.5f} RMSLE\")\n",
        "\n",
        "\n",
        "# Check your answer\n",
        "q_2.check()"
      ],
      "metadata": {
        "lines_to_next_cell": 0,
        "execution": {
          "iopub.status.busy": "2024-09-24T05:21:33.889847Z",
          "iopub.execute_input": "2024-09-24T05:21:33.890592Z",
          "iopub.status.idle": "2024-09-24T05:21:36.220422Z",
          "shell.execute_reply.started": "2024-09-24T05:21:33.89053Z",
          "shell.execute_reply": "2024-09-24T05:21:36.219198Z"
        },
        "trusted": true,
        "id": "1jyB45DdlJZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lines below will give you a hint or solution code\n",
        "#q_2.hint()\n",
        "#q_2.solution()"
      ],
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "uecRHZHelJZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------------------------------------\n",
        "\n",
        "The next question explores a way you can use PCA to detect outliers in the dataset (meaning, data points that are unusually extreme in some way). Outliers can have a detrimental effect on model performance, so it's good to be aware of them in case you need to take corrective action. PCA in particular can show you anomalous *variation* which might not be apparent from the original features: neither small houses nor houses with large basements are unusual, but it is unusual for small houses to have large basements. That's the kind of thing a principal component can show you.\n",
        "\n",
        "Run the next cell to show distribution plots for each of the principal components you created above."
      ],
      "metadata": {
        "id": "ISiPSRRLlJZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(\n",
        "    y=\"value\",\n",
        "    col=\"variable\",\n",
        "    data=X_pca.melt(),\n",
        "    kind='boxen',\n",
        "    sharey=False,\n",
        "    col_wrap=2,\n",
        ");"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T05:23:33.905293Z",
          "iopub.execute_input": "2024-09-24T05:23:33.906145Z",
          "iopub.status.idle": "2024-09-24T05:23:35.378946Z",
          "shell.execute_reply.started": "2024-09-24T05:23:33.906055Z",
          "shell.execute_reply": "2024-09-24T05:23:35.377493Z"
        },
        "trusted": true,
        "id": "9BDo9uUDlJZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, in each of the components there are several points lying at the extreme ends of the distributions -- outliers, that is.\n",
        "\n",
        "Now run the next cell to see those houses that sit at the extremes of a component:"
      ],
      "metadata": {
        "id": "_V-m3jCylJZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhận xét: Những giao dịch thuộc dạng \"Partial\" ở khu vực Edwards là outlier, vì chúng đại diện cho các tình huống đặc biệt (phân chia tài sản, thỏa thuận giữa các bên đồng sở hữu, v.v.). Những giá trị này có thể là outliers và nếu bạn muốn dự đoán giá trị của một căn nhà trên thị trường mở thông thường, việc loại bỏ các giao dịch này có thể hợp lý."
      ],
      "metadata": {
        "id": "t6jvQ2fqlJZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can change PC1 to PC2, PC3, or PC4\n",
        "component = \"PC1\"\n",
        "\n",
        "idx = X_pca[component].sort_values(ascending=False).index\n",
        "df.loc[idx, [\"SalePrice\", \"Neighborhood\", \"SaleCondition\"] + features]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T05:33:53.16551Z",
          "iopub.execute_input": "2024-09-24T05:33:53.165999Z",
          "iopub.status.idle": "2024-09-24T05:33:53.191735Z",
          "shell.execute_reply.started": "2024-09-24T05:33:53.165954Z",
          "shell.execute_reply": "2024-09-24T05:33:53.190573Z"
        },
        "trusted": true,
        "id": "BiBLOx8IlJZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "component = \"PC1\"\n",
        "\n",
        "pc1_value = X_pca[component].sort_values(ascending=False)\n",
        "pc1_value"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T05:35:08.186831Z",
          "iopub.execute_input": "2024-09-24T05:35:08.187961Z",
          "iopub.status.idle": "2024-09-24T05:35:08.202872Z",
          "shell.execute_reply.started": "2024-09-24T05:35:08.187898Z",
          "shell.execute_reply": "2024-09-24T05:35:08.201401Z"
        },
        "trusted": true,
        "id": "epbEM_CclJZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Outlier Detection\n",
        "\n",
        "Do you notice any patterns in the extreme values? Does it seem like the outliers are coming from some special subset of the data?\n",
        "\n",
        "After you've thought about your answer, run the next cell for the solution and some discussion."
      ],
      "metadata": {
        "id": "B6tIXK-ClJZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the solution (Run this cell to receive credit!)\n",
        "q_3.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T05:30:14.134966Z",
          "iopub.execute_input": "2024-09-24T05:30:14.135495Z",
          "iopub.status.idle": "2024-09-24T05:30:14.146206Z",
          "shell.execute_reply.started": "2024-09-24T05:30:14.135451Z",
          "shell.execute_reply": "2024-09-24T05:30:14.144817Z"
        },
        "trusted": true,
        "id": "rIywM-t0lJZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keep Going #\n",
        "\n",
        "[**Apply target encoding**](https://www.kaggle.com/ryanholbrook/target-encoding) to give a boost to categorical features."
      ],
      "metadata": {
        "id": "KlLLuMbBlJZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/feature-engineering/discussion) to chat with other learners.*"
      ],
      "metadata": {
        "id": "CQfNSbwUlJZX"
      }
    }
  ]
}